{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theep\\AppData\\Local\\Temp\\ipykernel_23672\\3988334339.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, PowerTransformer, MaxAbsScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pprint.pretty = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots 9 sensor df with title 'Material' \n",
    "# Can only intake a single trial number per df in dfs\n",
    "def plotdfs(dfs):\n",
    "    for df in dfs:\n",
    "        df_name = df['Material'].iloc[0]\n",
    "        trial_num = df['Trial'].iloc[0]\n",
    "        # Drop the 'Time' column\n",
    "        trial_df = df.drop(columns=['Trial', 'Material'])\n",
    "        \n",
    "        # Create a new plot for each trial\n",
    "        plt.figure()\n",
    "        \n",
    "        # Plot the data for the current trial\n",
    "        for col in trial_df.columns:\n",
    "            if col != 'Time':\n",
    "                plt.plot(trial_df['Time'], trial_df[col], label=f'S{col}')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Data')\n",
    "        plt.title(f'{df_name} Trial {trial_num}')\n",
    "        # plt.ylim(0, 10)\n",
    "        plt.xlim(0, 50)\n",
    "        plt.xticks(np.arange(0, 50, step=2))\n",
    "        # plt.yscale('log')\n",
    "        # Add legend\n",
    "        plt.legend()\n",
    "        \n",
    "        # Show the plot for the current trial\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folders = ['PLA-PDMS-EcoFlex_data\\\\EcoFlex', 'PLA-PDMS-EcoFlex_data\\\\PDMS', 'PLA-PDMS-EcoFlex_data\\\\PLA']\n",
    "data_dfs = []\n",
    "\n",
    "for folder in folders:\n",
    "    # List to store DataFrames from individual CSV files\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            # Read CSV file into a DataFrame\n",
    "            df = pd.read_csv(os.path.join(folder, file_name))\n",
    "            \n",
    "            # Extract trial number from file name\n",
    "            trial_number = file_name.split('_')[0]  # Assuming file names are in the format 'experiment_trialNumber.csv'\n",
    "            \n",
    "            # Add trial number as a new column\n",
    "            df['Trial'] = int(trial_number)\n",
    "            df['Material'] = folder.split('\\\\')[1]\n",
    "            df.rename(columns={\"255\": 'Time'}, inplace=True)\n",
    "            df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "            \n",
    "            # Append DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one large DataFrame\n",
    "    data_dfs.append(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cutoffs = [[29.5, 32, 30, 29.5, 30, 31, 31.5, 31.8, 31, 31.9, 31, 31],\n",
    "                [30.8, 30.5, 32.2, 31, 30, 32, 30, 30, 29.5, 30, 31.5, 30.8],\n",
    "                [37, 31.8, 35.5, 36.5, 30.5, 30.2, 29, 33, 32.5, 31, 30, 29.6]]\n",
    "for i in range(len(data_dfs)):\n",
    "    for j in range(len(data_dfs[i])):\n",
    "        data_dfs[i][j] = data_dfs[i][j][data_dfs[i][j]['Time'] < time_cutoffs[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_data_dfs = []\n",
    "for dfs in data_dfs:\n",
    "    temp = []\n",
    "    for df in dfs:\n",
    "        \n",
    "        \n",
    "        columns_to_average = df.columns.difference(['Time', 'Trial', 'Material'])\n",
    "        window_size = 10  # MA window size\n",
    "        new_df = pd.DataFrame()\n",
    "        # Keep Time and Trial num\n",
    "        new_df['Time'] = df['Time']\n",
    "        new_df['Trial'] = df['Trial']\n",
    "        new_df['Material'] = df['Material']\n",
    "\n",
    "        for col in columns_to_average:\n",
    "            new_df[f'{col} MA'] = df[col].rolling(window=window_size).mean() * 10e10\n",
    "\n",
    "        new_df.dropna(inplace=True)\n",
    "        temp.append(new_df)\n",
    "    ma_data_dfs.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 1 visualization for each material\n",
    "dfs_to_plot = [ma_data_dfs[0][0], ma_data_dfs[1][0], ma_data_dfs[2][0]]\n",
    "\n",
    "plotdfs(dfs_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic and linear fitting\n",
    "temp = dfs_to_plot[0]\n",
    "temp = temp[temp['Time'] <= 27]\n",
    "dfs_to_plot[0] = temp\n",
    "temp = dfs_to_plot[1]\n",
    "temp = temp[temp['Time'] <= 30]\n",
    "dfs_to_plot[1] = temp\n",
    "temp = dfs_to_plot[2]\n",
    "temp = temp[temp['Time'] <= 36.5]\n",
    "dfs_to_plot[2] = temp\n",
    "\n",
    "# fill data_pairs with 3 materials data, one sensor\n",
    "data_pairs = [(dfs_to_plot[0]['Time'].values, dfs_to_plot[0]['8 MA'].values),\n",
    "              (dfs_to_plot[1]['Time'].values, dfs_to_plot[1]['8 MA'].values),\n",
    "              (dfs_to_plot[2]['Time'].values, dfs_to_plot[2]['8 MA'].values)]\n",
    "\n",
    "# Define curve models\n",
    "def linear_func(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "def quadratic_func(x, a, b, c):\n",
    "    return a * x ** 2 + b * x + c\n",
    "\n",
    "# Fit data to each curve model\n",
    "curve_fits = {}\n",
    "for idx, (x_data, y_data) in enumerate(data_pairs, start=1):\n",
    "    linear_params, _ = curve_fit(linear_func, x_data, y_data)\n",
    "    linear_y_pred = linear_func(x_data, *linear_params)\n",
    "    linear_r_squared = r2_score(y_data, linear_y_pred)\n",
    "    \n",
    "    quadratic_params, _ = curve_fit(quadratic_func, x_data, y_data)\n",
    "    quadratic_y_pred = quadratic_func(x_data, *quadratic_params)\n",
    "    quadratic_r_squared = r2_score(y_data, quadratic_y_pred)\n",
    "    \n",
    "    curve_fits[idx] = {\n",
    "        'linear': (linear_params, linear_r_squared),\n",
    "        'quadratic': (quadratic_params, quadratic_r_squared)\n",
    "    }\n",
    "\n",
    "# Generate curves using fitted parameters and plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for idx, (x_data, y_data) in enumerate(data_pairs, start=1):\n",
    "    plt.subplot(2, 2, idx)\n",
    "    plt.scatter(x_data, y_data, label='Data')\n",
    "    x_curve = np.linspace(min(x_data), max(x_data), 1000)\n",
    "    \n",
    "    linear_params, linear_r_squared = curve_fits[idx]['linear']\n",
    "    y_curve_linear = linear_func(x_curve, *linear_params)\n",
    "    plt.plot(x_curve, y_curve_linear, label=f'Linear Fit (R-squared: {linear_r_squared:.2f})')\n",
    "    print(f\"Data Pair {idx} Linear Fit Coefficients: {linear_params}\")\n",
    "    \n",
    "    quadratic_params, quadratic_r_squared = curve_fits[idx]['quadratic']\n",
    "    y_curve_quadratic = quadratic_func(x_curve, *quadratic_params)\n",
    "    plt.plot(x_curve, y_curve_quadratic, label=f'Quadratic Fit (R-squared: {quadratic_r_squared:.2f})')\n",
    "    print(f\"Data Pair {idx} Quadratic Fit Coefficients: {quadratic_params}\")\n",
    "    \n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Data Pair {idx}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential fit for PLA\n",
    "\n",
    "x_data = dfs_to_plot[2]['Time'].values\n",
    "y_data = dfs_to_plot[2]['8 MA'].values\n",
    "\n",
    "# Define exponential function\n",
    "def exponential_func(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "\n",
    "# Fit data to exponential function\n",
    "params, covariance = curve_fit(exponential_func, x_data, y_data)\n",
    "\n",
    "# Generate fitted curve\n",
    "x_curve = np.linspace(min(x_data), max(x_data), 1000)\n",
    "y_curve = exponential_func(x_curve, *params)\n",
    "\n",
    "# Calculate R-squared value\n",
    "y_pred = exponential_func(x_data, *params)\n",
    "r_squared = r2_score(y_data, y_pred)\n",
    "\n",
    "# Plot data and fitted curve\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.plot(x_curve, y_curve, color='red', label='Fitted curve')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Exponential Curve Fitting')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'R-squared value: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress all data points and generate coefficients for each sensor in each trial\n",
    "\n",
    "coefficents = []\n",
    "for mat in ma_data_dfs:\n",
    "    # plotdfs(mat)\n",
    "    material_coefs = []\n",
    "    for df in mat:\n",
    "        x_data = df['Time'].values\n",
    "        temp = []\n",
    "        for i in range(9):\n",
    "            y_data = df[f'{i} MA'].values\n",
    "            try:\n",
    "                coef = np.polyfit(x_data, y_data, 2)\n",
    "                a, b, c = coef\n",
    "                temp.append(tuple((a, b, c)))\n",
    "            except:\n",
    "                print(df['Material'].iloc[0], df['Trial'].iloc[0])\n",
    "                # plotdfs([df])\n",
    "        material_coefs.append(temp)\n",
    "    coefficents.append(material_coefs)\n",
    "            \n",
    "coefficents = np.array(coefficents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented data and reshape data to prepare for training\n",
    "\n",
    "coef_x_data = []\n",
    "coef_y_data = []\n",
    "\n",
    "for material_num in range(len(coefficents)):\n",
    "    coef_augmented_data = []\n",
    "\n",
    "    for coef_num in range(3):\n",
    "        coefs = []\n",
    "\n",
    "        for trial_num in range(len(coefficents[material_num])):\n",
    "            for sensor in range(len(coefficents[material_num][trial_num])):\n",
    "                coefs.append(coefficents[material_num][trial_num][sensor][coef_num])\n",
    "\n",
    "        mu = np.average(coefs)\n",
    "        stdev = np.std(coefs)\n",
    "\n",
    "        values = np.random.default_rng().standard_t(107, 300)\n",
    "        values = (values * (stdev/np.sqrt(108))) + mu\n",
    "        coef_augmented_data.append(values)\n",
    "\n",
    "    coefs_paired = [(coef_augmented_data[0][i], coef_augmented_data[1][i], coef_augmented_data[2][i]) for i in range(len(coef_augmented_data[0]))]\n",
    "    \n",
    "    for e in coefs_paired:\n",
    "        coef_x_data.append(e)\n",
    "        coef_y_data.append(material_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 2, Predicted: [1]\n",
      "Actual: 2, Predicted: [1]\n",
      "Actual: 2, Predicted: [1]\n",
      "Actual: 2, Predicted: [1]\n",
      "12 324 0.962962962962963\n"
     ]
    }
   ],
   "source": [
    "# Training sklearn classifier\n",
    "\n",
    "# parameters = {\n",
    "#     'scaler': [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "#     'selector__threshold': [0, 0.001, 0.01],\n",
    "#     'classifier__C': [1, 10, 100, 1000]\n",
    "# }\n",
    "# pipe = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('selector', VarianceThreshold()),\n",
    "#     ('classifier', svm.SVC(kernel='linear', C=100))\n",
    "# ])\n",
    "clf = svm.SVC(kernel='linear', C=100)\n",
    "clf.fit(coef_x_data, coef_y_data)\n",
    "# pipe.fit(coef_x_data, coef_y_data)\n",
    "\n",
    "# grid = GridSearchCV(pipe, parameters, cv=2).fit(coef_x_data, coef_y_data)\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for mat in range(len(coefficents)):\n",
    "    for trial in coefficents[mat]:\n",
    "        for sensor in trial:\n",
    "            total += 1\n",
    "            val = clf.predict(sensor.reshape(1, -1))\n",
    "            if (mat != val):\n",
    "                print(f'Actual: {mat}, Predicted: {val}')\n",
    "                count += 1\n",
    "\n",
    "# print(grid.score(coef_x_data, coef_y_data))\n",
    "print(count, total, (1-(count/total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/SVC-96.3.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving classifier\n",
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'saved_models/SVC-96.3.pkl')\n",
    "\n",
    "# to load:\n",
    "# clf = joblib.load('saved_models\\SVC-96.3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notes for 2/19\n",
    "\n",
    "- Classifier is done, .963 accuracy\n",
    "- To predict on new data:\n",
    "    - Scale new data time axis to the same scale as input data - need to figure this out\n",
    "    - Should we retrain with fast pressure application to be able to downsample slow grasps?\n",
    "        - would have to see if faster presses still have as good performance on classifier\n",
    "\n",
    "- Object detection:\n",
    "    - paper had ~ 110,000 data \"sets\". Each set is a collection of 4*10 data from different types of sensors\n",
    "    - acquired data from 13 object * 20 grasps per object * ~400 sets of data from each grasp\n",
    "    - NO TIME FACTOR USED\n",
    "    - only using grasp data past a certain point\n",
    "    - used data from different grasp orientations and materials for each object\n",
    "\n",
    "    - Can we mount sensors on a hand?\n",
    "    - if this works, we don't need the camera for ground truth - groud truth is just the class of object in the trial\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
